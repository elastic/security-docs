[[tuning-anomaly-results]]
= Optimizing anomaly results

:description: Learn how to fine-tune and filter anomaly results.
:keywords: serverless, security, how-to

preview:[]

To gain clearer insights into real threats, you can tune the anomaly results. The following procedures help to reduce the number of false positives:

* <<rarely-used-processes,Tune results for rare applications and processes>>
* <<define-rule-threshold,Define an anomaly threshold for a job>>

[discrete]
[[rarely-used-processes]]
== Filter out anomalies from rarely used applications and processes

When anomalies include results from a known process that only runs occasionally,
you can filter out the unwanted results.

For example, to filter out results from a housekeeping process, named
`maintenanceservice.exe`, that only executes occasionally you need to:

. <<create-fiter-list,Create a filter list>>
. <<add-job-filter,Add the filter to the relevant job>>
. <<clone-job,Clone and rerun the job>> (optional)

[discrete]
[[create-fiter-list]]
=== Create a filter list

. Go to **Machine learning** → **Anomaly Detection** → **Settings**.
. Click **Filter Lists** and then **Create**.
+
The **Create new filter list** pane is displayed.
. Enter a filter list ID.
. Enter a description for the filter list (optional).
. Click **Add item**.
. In the **Items** textbox, enter the name of the process for which you want to
filter out anomaly results (`maintenanceservice.exe` in our example).
+
[role="screenshot"]
image::images/tuning-anomaly-results/-detections-machine-learning-filter-add-item.png[]
. Click **Add** and then **Save**.
+
The new filter appears in the Filter List and can be added to relevant jobs.

[discrete]
[[add-job-filter]]
=== Add the filter to the relevant job

. Go to **Machine learning** → **Anomaly Detection** → **Anomaly Explorer**.
. Navigate to the job results for which the filter is required. If the job results
are not listed, click **Edit job selection** and select the relevant job.
. In the **actions** column, click the gear icon and then select _Configure rules_.
+
The **Create Rule** window is displayed.
+
[role="screenshot"]
image::images/tuning-anomaly-results/-detections-machine-learning-rule-scope.png[]
. Select:
+
.. _Add a filter list to limit where the rule applies_.
.. The _WHEN_ statement for the relevant detector (`process.name` in our
example).
.. The _IS IN_ statement.
.. The filter you created as part of the <<create-fiter-list,Create a filter list>> procedure.
+
[TIP]
====
For more information, see
{ml-docs}/ml-configuring-detector-custom-rules.html[Customizing detectors with custom rules].
====
. Click **Save**.

[NOTE]
====
Changes to rules only affect new results. All anomalies found by the job
before the filter was added are still displayed.
====

[discrete]
[[clone-job]]
=== Clone and rerun the job

If you want to remove all the previously detected results for the process, you
must clone and run the cloned job.

[IMPORTANT]
====
Running the cloned job can take some time. Only run the job after you
have completed all job rule changes.
====

. Go to **Machine learning** → **Anomaly Detection** → **Jobs**.
. Navigate to the job for which you configured the rule.

// Should this be "Navigate to the job that you want to clone"?

. Optionally, expand the job row and click **JSON** to verify the configured filter
appears under `custom rules` in the JSON code.
. In the **actions** column, click the options menu (image:images/icons/boxesHorizontal.svg[Options menu]) and select **Clone job**.
+
The **Configure datafeed** page is displayed.
. Click **Data Preview** and check the data is displayed without errors.

// Unable to verify this step - don't think it exists anymore.

. Click **Next** until the **Job details** page is displayed.
. Enter a Job ID for the cloned job that indicates it is an iteration of the
original one. For example, append a number or a username to the original job
name, such as `windows-rare-network-process-2`.
+
[role="screenshot"]
image::images/tuning-anomaly-results/-detections-machine-learning-cloned-job-details.png[]
. Click **Next** and check the job validates without errors. You can ignore
warnings about multiple influencers.
. Click **Next** and then **Create job**.
+
The **Start <job name>** window is displayed.
+
// This page doesn't display.
+
[role="screenshot"]
image::images/tuning-anomaly-results/-detections-machine-learning-start-job-window.png[]
. Select the point of time from which the job will analyze anomalies.

// Users can't do this. I think their only option is to start the job in real time.

. Click **Start**.
+
After a while, results will start to appear on the **Anomaly Explorer** page.

[discrete]
[[define-rule-threshold]]
== Define an anomaly threshold for a job

// Unable to test these steps because I don't have the privs needed to enable/run ML jobs

Certain jobs use a high-count function to look for unusual spikes in
process events. For some processes, a burst of activity is a normal, such as
automation and housekeeping jobs running on server fleets. However, sometimes a
high-delta event count is unlikely to be the result of routine behavior. In
these cases, you can define a minimum threshold for when a high-event count is
considered an anomaly.

Depending on your anomaly detection results, you may want to set a
minimum event count threshold for the `packetbeat_dns_tunneling` job:

. Go to **Machine learning** → **Anomaly Detection** → **Anomaly Explorer**.
. Navigate to the job results for the `packetbeat_dns_tunneling` job. If the
job results are not listed, click **Edit job selection** and select
`packetbeat_dns_tunneling`.
. In the **actions** column, click the gear icon and then select
**Configure rules**.
+
The **Create Rule** window is displayed.
+
[role="screenshot"]
image::images/tuning-anomaly-results/-detections-machine-learning-ml-rule-threshold.png[]
. Select **Add numeric conditions for when the rule applies** and the following
`when` statement:
+
_WHEN actual IS GREATER THAN <X>_
+
Where `<X>` is the threshold above which anomalies are detected.
. Click **Save**.
. To apply the new threshold, rerun the job (**Job Management** → **Actions** → **Start datafeed**).

// Re-added the part that was missing from this step (might've not been migrated over), but am unable to verify this step because idk where the Job Management page is.
