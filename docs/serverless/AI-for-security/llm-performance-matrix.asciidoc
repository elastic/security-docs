[[security-llm-performance-matrix]]
= Large language model performance matrix

This page describes the performance of various large language models (LLMs) for different use cases in {elastic-sec}, based on our internal testing. To learn more about these use cases, refer to <<attack-discovery, Attack discovery>> or <<security-ai-assistant, AI Assistant>>. 

NOTE: `Excellent` is the best rating, followed by `Great`, then by `Good`, and finally by `Poor`.

[discrete]
== Proprietary models
Models from third-party LLM providers.  

[cols="1,1,1,1,1,1,1,1,1,1", options="header"]
|===
| *Feature*                     | *Model*         |                           |                    |                    |                   |           |               |                     |                     
|                               | *Claude 3: Opus*| *Claude 3.5: Sonnet v2* | *Claude 3.5: Sonnet* | *Claude 3.5: Haiku*| *Claude 3: Haiku* | *GPT-4o*  | *GPT-4o-mini* | **Gemini 1.5 Pro 002** | **Gemini 1.5 Flash 002** 
| *Assistant - General*         | Excellent       |  Excellent              | Excellent            | Excellent          | Excellent         | Excellent | Excellent     | Excellent           | Excellent 
| *Assistant - {esql} generation*| Excellent      |  Excellent              | Excellent            | Excellent          | Excellent         | Excellent | Great         | Excellent           | Poor 
| *Assistant - Alert questions* | Excellent       |  Excellent              | Excellent            | Excellent          | Excellent         | Excellent | Great         | Excellent           | Good 
| *Assistant - Knowledge retrieval* | Good        |  Excellent              | Excellent            | Excellent          | Excellent         | Excellent | Great         | Excellent           | Excellent
| *Attack Discovery*            | Great           |  Great                  | Excellent            | Poor               | Poor              | Great     | Poor          | Excellent           | Poor 
|===
 
[discrete]
== Open-source models
Models you can <<connect-to-byo-llm, deploy yourself>>.

[cols="1,1,1,1,1", options="header"]
|===
| *Feature*                     | *Model*         |            |                  |                         
|                               | *Mistral Nemo* | *LLama 3.2* | *LLama 3.1 405b* | *LLama 3.1 70b*
| *Assistant - General*         | Good           | Poor        | Good             |  Good 
| *Assistant - {esql} generation*| Good          | Poor        | Great            |  Good
| *Assistant - Alert questions* | Great          | Good        | Good             |  Poor
| *Assistant - Knowledge retrieval* | Good       | Poor        | Good             |  Poor
| *Attack Discovery*            | Poor           | Poor        | Poor             |  Poor
|===
 
