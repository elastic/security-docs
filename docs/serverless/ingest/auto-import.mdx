---
slug: /serverless/security/auto-import
title: Auto import
description: Use auto import to quickly ingest third-party data.
tags: [ 'serverless', 'security', 'how-to' ]
status: in review
---

<DocBadge template="technical preview" />

<DocCallOut title="Technical preview" color="warning">
This feature is in technical preview. It may change in the future, and you should exercise caution when using it in production environments. Elastic will work to fix any issues, but features in technical preview are not subject to the support SLA of GA features.
</DocCallOut>

This page explains how to use auto import. Auto import helps you quickly parse, map and ingest data from sources that don't work with one of Elastic's prebuilt integrations. It works by using a large language model (LLM) with specialized instructions to quickly create a custom integration for your specific data. For example, \[INSERT EXAMPLE?\] 

<DocCallOut title="Requirements">

- A working <DocLink slug="/serverless/security/llm-connector-guides" text="LLM connector"/>.
- \[a particular subscription type for ESS/serverless?\]
- A sample of the data you want to import, in JSON format. 

</DocCallOut>


## Create a new custom integration

1. In your ((elastic-sec)) deployment, click **Add integrations**.
2. Under **Can't find an integration?** click **Create new integration**.
3. Click **Create integration**.
4. Select an LLM connector. For more information about setting up an LLM connector, refer to <DocLink slug="/serverless/security/llm-connector-guides" text="LLM connector guides"/>. \[WHICH MODELS ARE RECOMMENDED/TESTED BY US? We should update the <DocLink slug="/serverless/security/llm-performance-matrix" text="LLM performance matrix"/>\]
5. Give your integration a **Title**, **Description**, and (optional) **Logo**. Click **Next**.
6. Define your package name and data stream, then upload a sample of your data in JSON format. Click **Analyze logs**, then wait for processing to complete. This may take several minutes.
7. After processing is complete, your data pipeline appears. \[Let's add a high quality screenshot of this page\]
8. You can review how each field is handled, and finetune it by clicking **Edit pipeline**. \[Let's add another high quality screenshot of this page\] 
9. When you're satisfied with your changes, click **Save**. 
10. Click **Add to Elastic**. 

A **Success** message appears. \[Screenshot\] Click **Add to an agent** to deploy your new integration and start collecting data, or click **View integration** to view detailed information about your new integration. 





