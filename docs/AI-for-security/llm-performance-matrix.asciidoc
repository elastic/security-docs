[[llm-performance-matrix]]
= Large language model performance matrix

This table describes the performance of various large language models (LLMs) for different use cases in {elastic-sec}, based on our internal testing. To learn more about these use cases, refer to <<attack-discovery, Attack discovery>> or <<security-assistant, AI Assistant>>.

[cols="1,1,1,1,1,1,1,1", options="header"]
|===
| *Feature*                     | *Model*               |                    |                   |         |                 |                       |                     
|                               | *Claude 3: Opus*      | *Claude 3.5: Sonnet* | *Claude 3: Haiku* | *GPT-4o* | *GPT-4 Turbo*  | **Gemini 1.5 Pro ** | **Gemini 1.5 Flash** 
| *Assistant - General*         | Excellent             | Excellent          | Excellent         | Excellent | Excellent     | Excellent             | Excellent 
| *Assistant - {esql} generation*| Great                 | Great              | Poor              | Excellent | Poor          | Good                 | Poor 
| *Assistant - Alert questions* | Excellent             | Excellent          | Excellent         | Excellent | Poor          | Excellent             | Good 
| *Attack discovery*            | Excellent             | Excellent            | Poor              | Poor      | Good        | Great                 | Poor 
|===
 