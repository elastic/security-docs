[[llm-performance-matrix]]
= Large language model performance matrix

This table describes the performance of various LLMs for different use-cases in {elastic-sec}, based on our internal testing. To learn more about these use-cases, refer to <<attack-discovery, Attack discovery>> or <<security-assistant, AI assistant>>.

[cols="1,1,1,1,1,1,1", options="header"]
|===
| *Feature*                     | *Model*               |                    |                   |         |              |             
|                               | *Claude 3: Opus*      | *Claude 3: Sonnet* | *Claude 3: Haiku* | *GPT-4o* | *GPT-4 Turbo*| *GPT-4 32K* 

| *Assistant - General*         | Excellent             | Excellent          | Excellent         | Excellent | Excellent     | Excellent
| *Assistant - {{esql}} Generation*| Great                 | Great              | Poor              | Excellent | Poor          | Excellent
| *Assistant - Alert Questions* | Excellent             | Excellent          | Excellent         | Excellent | Poor          | Good (limited context)
| *Attack Discovery*            | Excellent             | Great              | Poor              | Poor      | Good          | Good (limited context)
|===
