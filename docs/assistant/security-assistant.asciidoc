[[security-assistant]]
= AI Assistant

:frontmatter-description: The Elastic AI Assistant is a generative AI open-code chat assistant.
:frontmatter-tags-products: [security]
:frontmatter-tags-content-type: [overview]
:frontmatter-tags-user-goals: [get-started]

The Elastic AI Assistant utilizes generative AI to bolster your cybersecurity operations team. It allows users to interact with {elastic-sec} for tasks such as alert investigation, incident response, and query generation or conversion using natural language and much more.

AI Assistant can connect to multiple LLM providers so you can select the best model for your needs.

[role="screenshot"]
image::images/assistant-basic-view.png[Image of AI Assistant chat window,90%]

WARNING: The Elastic AI Assistant is designed to enhance your analysis with smart dialogues. Its capabilities are still developing. Users should exercise caution as the quality of its responses might vary. Your insights and feedback will help us improve this feature. Always cross-verify AI-generated advice for accuracy.

.Recommended models
[sidebar]
--
While AI Assistant is compatible with many different models, our testing found increased quality with Azure 32k, and faster and more cost-effective responses with Claude 3 Haiku and OpenAI GPT4 Turbo.
--

.Requirements
[sidebar]
--
* The Elastic AI Assistant and Generative AI connector are available in {stack} versions 8.8.1 and later. The Generative AI connector is renamed to OpenAI connector in 8.11.0.

* This feature requires an https://www.elastic.co/pricing[Enterprise subscription].

* To use AI Assistant, you need at least the **Elastic AI Assistant : All** and **Actions and Connectors : Read** {kibana-ref}/kibana-privileges.html[privileges].

* To set up AI Assistant, you need the **Actions and Connectors : All** {kibana-ref}/kibana-privileges.html[privilege].

* You need an account with a third-party generative AI provider, which AI Assistant uses to generate responses. Supported providers are OpenAI, Azure OpenAI Service, and Amazon Bedrock.
--

[discrete]
[[data-information]]
== Your data and AI Assistant

Elastic does not store or examine prompts or results used by AI Assistant, or use this data for model training. This includes anything you send the model, such as alert or event data, detection rule configurations, queries, and prompts. However, any data you provide to AI Assistant will be processed by the third-party large language model (LLM) provider you connected to as part of AI Assistant setup.

Elastic does not control third-party tools, and assumes no responsibility or liability for their content, operation, or use, nor for any loss or damage that may arise from your using such tools. Please exercise caution when using AI tools with personal, sensitive, or confidential information. Any data you submit may be used by the provider for AI training or other purposes. There is no guarantee that the provider will keep any information you provide secure or confidential. You should familiarize yourself with the privacy practices and terms of use of any generative AI tools prior to use.

NOTE: Elastic can automatically anonymize event data that you provide to AI Assistant as context. To learn more, refer to <<configure-ai-assistant, Configure AI Assistant>>.


[discrete]
[[set-up-ai-assistant]]
== Set up AI Assistant

You must create a generative AI connector before you can use AI Assistant. 

For more information about setting up generative AI connectors, refer to <<assistant-connect-to-bedrock>>, <<assistant-connect-to-openai>>, or <<assistant-connect-to-azure-openai>>.

[discrete]
[[start-chatting]]
== Start chatting

To open AI Assistant, select the **AI Assistant** button in the top toolbar from anywhere in the {security-app}. You can also use the keyboard shortcut *Cmd + ;* (or *Ctrl + ;* on Windows). 

[role="screenshot"]
image::images/ai-assistant-button.png[AI Assistant button,150]

This opens the *Welcome* chat interface, where you can ask general questions about {elastic-sec}.

You can also chat with AI Assistant from several particular pages in {elastic-sec} where you can easily send context-specific data and prompts to AI Assistant.

* <<view-alert-details, Alert details>> or Event details flyout: Click *Chat* while viewing the details of an alert or event.
* <<rules-ui-management, Rules page>>: Select one or more rules, then click the **Chat** button at the top right of the page.
* <<data-quality-dash, Data Quality dashboard>>: Select the *Incompatible fields* tab, then click *Chat*. (This is only available for fields marked red, indicating they're incompatible).
* <<timelines-ui, Timeline>>: Select the *Security Assistant* tab.

NOTE: Each user's chat history and custom quick prompts are automatically saved, so you can leave ((elastic-sec)) and return to pick up a conversation later.

[discrete]
[[interact-with-assistant]]
== Interact with AI Assistant

Use these features to adjust and act on your conversations with AI Assistant:

* Select a _system prompt_ at the beginning of a conversation to establish how detailed and technical you want AI Assistant's answers to be.
+
[role="screenshot"]
image::images/system-prompt.gif[The system prompt drop-down menu,90%]
+
System prompts provide context to the model, informing its response. To create a custom system prompt, open the system prompts dropdown menu and click *+ Add new system prompt...*.

* Select a _quick prompt_ at the bottom of the chat window to get help writing a prompt for a specific purpose, such as summarizing an alert or converting a query from a legacy SIEM to {elastic-sec}.
+
[role="screenshot"]
image::images/quick-prompts.png[Quick prompts highlighted below a conversation,90%]
+
Quick prompt availability varies based on context — for example, the **Alert summarization** quick prompt appears when you open AI Assistant while viewing an alert. To customize existing quick prompts and create new ones, click *Add Quick prompt*.

* In an active conversation, you can use the inline actions that appear on messages to incorporate AI Assistant's responses into your workflows:

** *Add note to timeline* (image:images/icon-add-note.png[Add note icon,16,16]): Add the selected text to your currently active Timeline as a note.
** *Add to existing case* (image:images/icon-add-to-case.png[Add to case icon,19,16]): Add a comment to an existing case using the selected text.
** *Copy to clipboard* (image:images/icon-copy.png[Copy to clipboard icon,17,18]): Copy the text to clipboard to paste elsewhere. Also helpful for resubmitting a previous prompt.
** *Add to timeline* (image:images/icon-add-to-timeline.png[Add to timeline icon,17,18]): Add a filter or query to Timeline using the text. This button appears for particular queries in AI Assistant's responses.
+
TIP: Be sure to specify which language you'd like AI Assistant to use when writing a query. For example: "Can you generate an Event Query Language query to find four failed logins followed by a successful login?"

[discrete]
[[configure-ai-assistant]]
== Configure AI Assistant
The *Settings* menu (image:images/icon-settings.png[Settings icon,17,17]) allows you to configure default conversations, quick prompts, system prompts, and data anonymization.

[role="screenshot"]
image::images/assistant-settings-menu.png[AI Assistant's settings menu, open to the Conversations tab]

The *Settings* menu has the following tabs:

* **Conversations:** When you open AI Assistant from certain pages, such as Timeline or Alerts, it defaults to the relevant conversation type. Choose the default system prompt for each conversation type, the connector, and model (if applicable). The **Streaming** setting controls whether AI Assistant's responses appear word-by-word (streamed), or as a complete block of text. Streaming is currently only available for OpenAI models.
* **Quick Prompts:** Modify existing quick prompts or create new ones. To create a new quick prompt, type a unique name in the *Name* field, then press *enter*. Under *Prompt*, enter or update the quick prompt's text. 
* **System Prompts:** Edit existing system prompts or create new ones. To create a new system prompt, type a unique name in the *Name* field, then press *enter*. Under *Prompt*, enter or update the system prompt's text. Under *Contexts*, select where the system prompt should appear.
+
NOTE: To delete a custom prompt, open the *Name* drop-down menu, hover over the prompt you want to delete, and click the *X* that appears. You cannot delete the default prompts.

* **Anonymization:** Select fields to include as plaintext, to obfuscate, and to not send when you provide events to AI Assistant as context. <<ai-assistant-anonymization, Learn more>>.

* **Knowledge base:** Provide additional context to AI Assistant so it can answer questions about {esql} and alerts in your environment. <<ai-assistant-knowledge-base, Learn more>>.

[discrete]
[[ai-assistant-anonymization]]
=== Anonymization

The **Anonymization** tab of the AI Assistant settings menu allows you to define default data anonymization behavior for events you send to AI Assistant. Fields with **Allowed** toggled on are included in events provided to AI Assistant. **Allowed** fields with **Anonymized** set to **Yes** are included, but with their values obfuscated.

[role="screenshot"]
image::images/assistant-anonymization-menu.png[AI Assistant's settings menu, open to the Anonymization tab]

The fields on this list are among those most likely to provide relevant context to AI Assistant. Fields with *Allowed* toggled on are included. *Allowed* fields with *Anonymized* set to *Yes* are included, but with their values obfuscated.

The *Show anonymized* toggle controls whether you see the obfuscated or plaintext versions of the fields you sent to AI Assistant. It doesn't control what gets obfuscated — that's determined by the anonymization settings. It also doesn't affect how event fields appear _before_ being sent to AI Assistant. Instead, it controls how fields that were already sent and obfuscated appear to you.

When you include a particular event as context, such as an alert from the Alerts page, you can adjust anonymization behavior for the specific event. Be sure the anonymization behavior meets your specifications before sending a message with the event attached.

[discrete]
[[ai-assistant-knowledge-base]]
=== Knowledge base
beta::[]

The **Knowledge base** tab of the AI Assistant settings menu allows you to enable AI Assistant to answer questions about the Elastic Search Query Language ({esql}), and about alerts in your environment.

[discrete]
[[rag-for-esql]]
==== Knowledge base for {esql}

NOTE: {esql} is enabled by default in {kib}. It can be
disabled using the `enableESQL` setting from the
{kibana-ref}/advanced-options.html[Advanced Settings]. This will hide the {esql} user interface from various applications. However, users will be able to access existing {esql} artifacts like saved searches and visualizations.

IMPORTANT: {esql} queries generated by AI Assistant might require additional validation. To ensure they're correct, refer to the {ref}/esql-language.html[{esql} documentation]. 

When this feature is enabled, AI Assistant can help you write an {esql} query for a particular use case, or answer general questions about {esql} syntax and usage. To enable AI Assistant to answer questions about {esql}:

. Enable the Elastic Learned Sparse EncodeR (ELSER). This model provides additional context to the third-party LLM. To learn more, refer to {ml-docs}/ml-nlp-elser.html#download-deploy-elser[Configure ELSER].
. Initialize the knowledge base by clicking *Initialize*.
. Turn on the *Knowledge Base* option.
. Click *Save*. The knowledge base is now active. A quick prompt for {esql} queries becomes available, which provides a good starting point for your {esql} conversations and questions. 

NOTE: To update AI Assistant so that it uses the most current {esql} documentation to answer your questions, click **Delete** next to **Knowledge Base**, and toggle the **Knowledge Base** slider off and then on. 

[discrete]
[[rag-for-alerts]]
==== Knowledge base for alerts
When this feature is enabled, AI Assistant will receive multiple alerts as context for each of your prompts. It will receive alerts from the last 24 hours that have a status of `open` or `acknowledged`, ordered first by risk score, then by recency. Building block alerts are excluded. This enables it to answer questions about multiple alerts in your environment, rather than just the individual alerts you choose to include as context. 

To enable RAG for alerts:

. Turn on the **Alerts** setting.
. Use the slider to select the number of alerts to send to AI Assistant. 
+
[role="screenshot"]
image::images/knowledge-base-settings.png["AI Assistant's settings menu open to the Knowledge Base tab",75%]

NOTE: Including a large number of alerts may cause your request to exceed the maximum token length of your third-party generative AI provider. If this happens, try selecting a lower number of alerts to send.

[discrete]
[[ai-assistant-queries]]
### Get the most from your queries

Elastic AI Assistant helps you take full advantage of the {elastic-sec} platform to improve your security operations. Its ability to assist you depends on the specificity and detail of your questions. The more context and detail you provide, the more tailored and useful its responses will be. 

To maximize its usefulness, consider using more detailed prompts or asking for additional information. For instance, after asking for an {esql} query example, you could ask a follow-up question like, “Could you give me some other examples?” You can also ask for clarification or further exposition, for example "Please provide comments explaining the query you just gave."

In addition to practical advice, AI Assistant can offer conceptual advice, tips, and best practices for enhancing your security measures. You can ask it, for example:

* “How do I set up a {ml} job in {elastic-sec} to detect anomalies in network traffic volume over time?”
* “I need to monitor for unusual file creation patterns that could indicate ransomware activity. How would I construct this query using EQL?”


include::ai-alert-triage.asciidoc[leveloffset=+1]
include::azure-openai-setup.asciidoc[leveloffset=+1]
include::connect-to-openai.asciidoc[leveloffset=+1]
include::connect-to-bedrock.asciidoc[leveloffset=+1]
