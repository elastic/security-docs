[[assistant-connect-to-azure-openai]]
= Connect to Azure OpenAI

This page provides step-by-step instructions for setting up an Azure OpenAI connector for the first time. This connector type enables you to leverage large language models (LLMs) within {kib}. You'll first need to configure Azure, then configure the connector in {kib}.

[discrete]
== Configure Azure

[discrete]
=== Configure a deployment

First, set up an Azure OpenAI deployment:

. Log in to the Azure console and search for Azure OpenAI.
. In **Azure AI services**, select **Create**.
. For the **Project Details**, select your subscription and resource group. If you don't have a resource group, select **Create new** to make one.
. For **Instance Details**, select the desired region and specify a name, such as `example-deployment-openai`.
. Select the **Standard** pricing tier, then click **Next**.
. Configure your network settings, click **Next**, optionally add tags, then click **Next**.
. Review your deployment settings, then click **Create**. When complete, select **Go to resource**.

The following video demonstrates these steps.

=======
++++
<script type="text/javascript" async src="https://play.vidyard.com/embed/v4.js"></script>
<img
  style="width: 100%; margin: auto; display: block;"
  class="vidyard-player-embed"
  src="https://play.vidyard.com/7NEa5VkVJ67RHWBuK8qMXA.jpg"
  data-uuid="7NEa5VkVJ67RHWBuK8qMXA"
  data-v="4"
  data-type="inline"
/>
</br>
++++
=======

[discrete]
=== Configure keys

Next, create access keys for the deployment:

. From within your Azure OpenAI deployment, select **Click here to manage keys**.
. Store these keys in a secure location. You'll need them later.

The following video demonstrates these steps.

=======
++++
<script type="text/javascript" async src="https://play.vidyard.com/embed/v4.js"></script>
<img
  style="width: 100%; margin: auto; display: block;"
  class="vidyard-player-embed"
  src="https://play.vidyard.com/cQXw96XjaeF4RiB3V4EyTT.jpg"
  data-uuid="cQXw96XjaeF4RiB3V4EyTT"
  data-v="4"
  data-type="inline"
/>
</br>
++++
=======

[discrete]
=== Configure a model

Now, set up the Azure OpenAI model:

. From within your Azure OpenAI deployment, select **Model deployments**, then click **Manage deployments**.
. On the **Deployments** page, select **Create new deployment**.
. Under **Select a model**, choose `gpt-4` or `gpt-4-32k`.
.. If you select `gpt-4`, set the **Model version** to `0125-Preview`. 
.. If you select `gpt-4-32k`, set the **Model version** to `default`.
+
IMPORTANT: The models available to you will depend on https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability[region availability]. For best results, use `GPT 4 Turbo version 0125-preview` or `GPT 4-32k` with the maximum Tokens-Per-Minute (TPM) capacity. In most regions, the GPT 4 Turbo model offers the largest supported context window.
+
. Under **Deployment type**, select **Standard**.
. Name your deployment.
. Slide the **Tokens per Minute Rate Limit** to the maximum. This example supports 80,000 TPM, but other regions might support higher limits. Click **Create**.

The following video demonstrates these steps.

=======
++++
<script type="text/javascript" async src="https://play.vidyard.com/embed/v4.js"></script>
<img
  style="width: 100%; margin: auto; display: block;"
  class="vidyard-player-embed"
  src="https://play.vidyard.com/PdadFyV1p1DbWRyCr95whT.jpg"
  data-uuid="PdadFyV1p1DbWRyCr95whT"
  data-v="4"
  data-type="inline"
/>
</br>
++++
=======

[discrete]
== Configure Elastic AI Assistant

Finally, configure the connector in {kib}:

. Log in to {kib}.
. Go to **Stack Management → Connectors → Create connector → OpenAI**.
. Name your connector.
. (Optional) Add one of the following strings if you want to use a model other than the default:
.. For Turbo: `Azure OpenAI (GPT-4 Turbo v. 0125)`
.. For 32k: `Azure OpenAI (GPT-4-32k)`
. For **Select an OpenAI provider**, choose **Azure OpenAI**.
. The easiest way to update the **URL** field is to navigate to your deployment in Azure AI Studio and select **Open in Playground**. 
.. Select **View code** and change the **Sample code** to `Curl`. Without including the quotes, highlight and copy the URL, then paste it into the **URL** field in {kib}. 
.. (Optional) Alternatively, refer to the https://learn.microsoft.com/en-us/azure/ai-services/openai/reference[API documentation] to learn how to create the URL manually. 
. Under **API key**, enter one of your API keys.
. Click **Save and test**, then click **Run**.

Your LLM connector is now configured. The following video demonstrates these steps.

=======
++++
<script type="text/javascript" async src="https://play.vidyard.com/embed/v4.js"></script>
<img
  style="width: 100%; margin: auto; display: block;"
  class="vidyard-player-embed"
  src="https://play.vidyard.com/RQZVcnXHokC3RcV6ZB2pmF.jpg"
  data-uuid="RQZVcnXHokC3RcV6ZB2pmF"
  data-v="4"
  data-type="inline"
/>
</br>
++++
=======
