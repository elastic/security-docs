[[assistant-connect-to-azure-openai]]
= Connect to Azure OpenAI

This page provides step-by-step instructions for setting up an Azure OpenAI connector for the first time. This connector type enables you to leverage large language models (LLMs) within {kib}. You'll first need to configure Azure, then configure the connector in {kib}.

[discrete]
== Configure Azure

[discrete]
=== Configure a deployment

First, set up an Azure OpenAI deployment:

. Log in to the Azure console and search for Azure OpenAI.
. In **Azure AI services**, select **Create**.
. For the **Project Details**, select your subscription and resource group. If you don't have a resource group, select **Create new** to make one.
. For **Instance Details**, select the desired region and specify a name, such as `example-deployment-openai`.
. Select the **Standard** pricing tier, then click **Next**.
. Configure your network settings, click **Next**, optionally add tags, then click **Next**.
. Review your deployment settings, then click **Create**. When complete, select **Go to resource**.

The following video demonstrates these steps.

=======
++++
<script type="text/javascript" async src="https://play.vidyard.com/embed/v4.js"></script>
<img
  style="width: 100%; margin: auto; display: block;"
  class="vidyard-player-embed"
  src="https://play.vidyard.com/7NEa5VkVJ67RHWBuK8qMXA.jpg"
  data-uuid="7NEa5VkVJ67RHWBuK8qMXA"
  data-v="4"
  data-type="inline"
/>
</br>
++++
=======

[discrete]
=== Configure keys

Next, create access keys for the deployment:

. From within your Azure OpenAI deployment, select **Click here to manage keys**.
. Store your keys in a secure location.

The following video demonstrates these steps.

=======
++++
<script type="text/javascript" async src="https://play.vidyard.com/embed/v4.js"></script>
<img
  style="width: 100%; margin: auto; display: block;"
  class="vidyard-player-embed"
  src="https://play.vidyard.com/cQXw96XjaeF4RiB3V4EyTT.jpg"
  data-uuid="cQXw96XjaeF4RiB3V4EyTT"
  data-v="4"
  data-type="inline"
/>
</br>
++++
=======

[discrete]
=== Configure a model

Now, set up the Azure OpenAI model:

. From within your Azure OpenAI deployment, select **Model deployments**, then click **Manage deployments**.
. On the **Deployments** page, select **Create new deployment**.
. Under **Select a model**, choose `gpt-4` or `gpt-4-32k`.
** If you select `gpt-4`, set the **Model version** to `0125-Preview`. 
** If you select `gpt-4-32k`, set the **Model version** to `default`.
+
IMPORTANT: The models available to you depend on https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability[region availability]. For best results, use `GPT-4o 2024-05-13` with the maximum Tokens-Per-Minute (TPM) capacity. For more information on how different models perform for different tasks, refer to the <<llm-performance-matrix>>.
+
. Under **Deployment type**, select **Standard**.
. Name your deployment.
. Slide the **Tokens per Minute Rate Limit** to the maximum. The following example supports 80,000 TPM, but other regions might support higher limits. 
. Click **Create**.

The following video demonstrates these steps.

=======
++++
<script type="text/javascript" async src="https://play.vidyard.com/embed/v4.js"></script>
<img
  style="width: 100%; margin: auto; display: block;"
  class="vidyard-player-embed"
  src="https://play.vidyard.com/PdadFyV1p1DbWRyCr95whT.jpg"
  data-uuid="PdadFyV1p1DbWRyCr95whT"
  data-v="4"
  data-type="inline"
/>
</br>
++++
=======

[discrete]
== Configure Elastic AI Assistant

Finally, configure the connector in {kib}:

. Log in to {kib}.
. Go to **Stack Management → Connectors → Create connector → OpenAI**.
. Give your connector a name to help you keep track of different models, such as `Azure OpenAI (GPT-4 Turbo v. 0125)`.
. For **Select an OpenAI provider**, choose **Azure OpenAI**.
. Update the **URL** field. We recommend doing the following:
.. Navigate to your deployment in Azure AI Studio and select **Open in Playground**. The **Chat playground** screen displays. 
.. Select **View code**, then from the drop-down, change the **Sample code** to `Curl`. 
.. Highlight and copy the URL without the quotes, then paste it into the **URL** field in {kib}. 
.. (Optional) Alternatively, refer to the https://learn.microsoft.com/en-us/azure/ai-services/openai/reference[API documentation] to learn how to create the URL manually. 
. Under **API key**, enter one of your API keys.
. Click **Save & test**, then click **Run**.

Your LLM connector is now configured. The following video demonstrates these steps.

=======
++++
<script type="text/javascript" async src="https://play.vidyard.com/embed/v4.js"></script>
<img
  style="width: 100%; margin: auto; display: block;"
  class="vidyard-player-embed"
  src="https://play.vidyard.com/RQZVcnXHokC3RcV6ZB2pmF.jpg"
  data-uuid="RQZVcnXHokC3RcV6ZB2pmF"
  data-v="4"
  data-type="inline"
/>
</br>
++++
=======
